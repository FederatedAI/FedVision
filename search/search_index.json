{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to FedVision \u00b6 FedVision is a Visual Object Detection Platform Powered by Federated Learning quick start \u00b6 install deploy toolkit pip install -U pip && pip install fedvision_deploy_toolkit generate deploy template fedvision-deploy template generate modify generated template deploy_config_template.yaml according to comments. start service fedvision-deploy deploy deploy deploy_config_template.yaml run examples in deploy directory 1) download data with script in ${deploy_dir}/data 2) run examples with script in ${deploy_dir}/examples","title":"Home"},{"location":"#welcome-to-fedvision","text":"FedVision is a Visual Object Detection Platform Powered by Federated Learning","title":"Welcome to FedVision"},{"location":"#quick-start","text":"install deploy toolkit pip install -U pip && pip install fedvision_deploy_toolkit generate deploy template fedvision-deploy template generate modify generated template deploy_config_template.yaml according to comments. start service fedvision-deploy deploy deploy deploy_config_template.yaml run examples in deploy directory 1) download data with script in ${deploy_dir}/data 2) run examples with script in ${deploy_dir}/examples","title":"quick start"},{"location":"apis/cluster/","text":"manager \u00b6 fedvision.framework.cluster.manager \u00b6 ClusterManager \u00b6 Enroll ( self , request , context ) \u00b6 rpc server impl: process tasker enroll request Parameters: Name Type Description Default request REQ required context ServicerContext required Returns: Type Description AsyncGenerator[fedvision.framework.protobuf.cluster_pb2.REP, NoneType] Source code in fedvision/framework/cluster/manager.py async def Enroll ( self , request : cluster_pb2 . Enroll . REQ , context : grpc . aio . ServicerContext , ) -> AsyncGenerator [ cluster_pb2 . Enroll . REP , None ]: \"\"\" rpc server impl: process tasker enroll request Args: request: context: Returns: \"\"\" self . debug ( f \"cluster worker enroll request: { pretty_pb ( request ) } \" ) if self . has_worker ( request . worker_id ): yield cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . ALREADY_ENROLL ) return worker = self . add_worker ( request . worker_id , request . worker_ip , request . max_tasks , request . port_start , request . port_end , ) self . debug ( f \"cluster worker enroll success: worker: { request . worker_id } \" ) yield cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . ENROLL_SUCCESS ) while self . has_worker ( request . worker_id ): try : task = await worker . wait_next_task ( timeout = 5 ) except asyncio . TimeoutError : continue self . debug ( f \"task ready: job_id= { task . job_id } , task_id= { task . task_id } , task_type= { task . task_type } \" ) rep = cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . TASK_READY , task = task ) self . debug ( f \"response task( { task . task_id } , { task . task_type } ) to worker { request . worker_id } \" ) yield rep self . remove_worker ( request . worker_id ) TaskResourceRequire ( self , request , context ) async \u00b6 Missing associated documentation comment in .proto file. Source code in fedvision/framework/cluster/manager.py async def TaskResourceRequire ( self , request , context ): worker , endpoints = await self . dispatch ( resource = { \"endpoints\" : request . num_endpoints } ) if worker is None : return cluster_pb2 . TaskResourceRequire . REP ( status = cluster_pb2 . TaskResourceRequire . FAILED ) response = cluster_pb2 . TaskResourceRequire . REP ( status = cluster_pb2 . TaskResourceRequire . SUCCESS , worker_id = worker . worker_id ) for endpoint in endpoints : response . endpoints . append ( endpoint ) return response TaskSubmit ( self , request , context ) async \u00b6 service for master: submit task to cluster Source code in fedvision/framework/cluster/manager.py async def TaskSubmit ( self , request : cluster_pb2 . TaskSubmit . REQ , context : grpc . aio . ServicerContext ) -> cluster_pb2 . TaskSubmit . REP : try : task = request . task if not task . assignee : worker , _ = await self . dispatch () await worker . put_task ( task = task ) else : await self . _alive_workers [ task . assignee ] . put_task ( task = task ) return cluster_pb2 . TaskSubmit . REP ( status = cluster_pb2 . TaskSubmit . SUCCESS ) except Exception as e : self . exception ( f \"handle task submit failed: { e } \" ) return cluster_pb2 . TaskSubmit . REP ( status = cluster_pb2 . TaskSubmit . FAILED ) UpdateTaskStatus ( self , request , context ) async \u00b6 process task status update request Parameters: Name Type Description Default request REQ required context ServicerContext required Returns: Type Description REP Source code in fedvision/framework/cluster/manager.py async def UpdateTaskStatus ( self , request : cluster_pb2 . UpdateStatus . REQ , context : grpc . aio . ServicerContext ) -> cluster_pb2 . UpdateStatus . REP : \"\"\" process task status update request Args: request: context: Returns: \"\"\" if request . worker_id not in self . _alive_workers : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . FAILED ) await self . _alive_workers [ request . worker_id ] . update_heartbeat () if not request . task_id : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . SUCCESS ) if not request . task_id not in self . _tasks_status : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . FAILED ) self . debug ( f \"update task status: { request . task_id } to { request . task_status } \" ) self . _tasks_status [ request . task_id ] = request . task_status return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . SUCCESS ) worker \u00b6 fedvision.framework.cluster.worker \u00b6 ClusterWorker \u00b6 start ( self ) async \u00b6 start worker enroll to manager start heartbeat loop start task exec loop process tasks Source code in fedvision/framework/cluster/worker.py async def start ( self ): \"\"\" start worker 1. enroll to manager 2. start heartbeat loop 3. start task exec loop 4. process tasks Returns: \"\"\" self . info ( f \"starting worker { self . _worker_id } \" ) self . info ( f \"staring grpc channel to cluster manager\" ) self . _channel = grpc . aio . insecure_channel ( self . _manager_address , options = [ ( \"grpc.max_send_message_length\" , 512 * 1024 * 1024 ), ( \"grpc.max_receive_message_length\" , 512 * 1024 * 1024 ), ], ) self . _stub = cluster_pb2_grpc . ClusterManagerStub ( self . _channel ) self . info ( f \"sending enroll request to cluster manager\" ) response_stream : AsyncIterable [ cluster_pb2 . Enroll . REP ] = self . _stub . Enroll ( cluster_pb2 . Enroll . REQ ( worker_id = self . _worker_id , worker_ip = self . _worker_ip , max_tasks = self . _max_tasks , port_start = self . _port_start , port_end = self . _port_end , ) ) first_response = True try : async for response in response_stream : if first_response : if response . status == cluster_pb2 . Enroll . ALREADY_ENROLL : raise FedvisionWorkerException ( f \"worker< { self . _worker_id } > already enrolled, use new name or remove it from manager\" ) if response . status != cluster_pb2 . Enroll . ENROLL_SUCCESS : raise FedvisionWorkerException ( f \"worker< { self . _worker_id } >enroll failed with unknown status: { response . status } \" ) self . info ( f \"worker< { self . _worker_id } >success enrolled to cluster manager\" ) async def _co_update_status (): while True : try : request = await asyncio . wait_for ( self . _task_status . get (), self . _heartbeat_interval ) except asyncio . TimeoutError : self . trace ( \"wait task status timeout. sending heartbeat request\" ) request = cluster_pb2 . UpdateStatus . REQ ( worker_id = self . _worker_id ) try : update_response = await self . _stub . UpdateTaskStatus ( request ) except grpc . aio . AioRpcError as _e : self . error ( f \"can't send heartbeat to manager, { _e } \" ) self . _stop_event . set () return if ( update_response . status != cluster_pb2 . UpdateStatus . SUCCESS ): self . error ( f \"update status failed, please check manager status\" ) self . info ( \"starting heartbeat loop\" ) self . _asyncio_task_collection = [ asyncio . create_task ( _co_update_status ()), ] self . info ( \"heartbeat loop started\" ) self . info ( f \"starting task execute loop\" ) self . _asyncio_task_collection . append ( asyncio . create_task ( self . _co_task_execute_loop ()) ) self . info ( f \"task execute loop started\" ) first_response = False continue # fetch tasks if response . status != cluster_pb2 . Enroll . TASK_READY : raise FedvisionWorkerException ( f \"expect status { cluster_pb2 . Enroll . TASK_READY } , got { response . status } \" ) self . trace_lazy ( f \"response < {{ response }} > got\" , response = lambda : pretty_pb ( response ) ) try : task_id = response . task . task_id task_type = response . task . task_type task_class = extensions . get_task_class ( task_type ) if task_class is None : self . error ( f \"task type { task_type } not found\" ) raise FedvisionExtensionException ( f \"task type { task_type } not found\" ) task = task_class . deserialize ( response . task ) await self . _task_queue . put ( task ) self . trace ( f \"put task in queue: task_id= { task_id } \" ) except FedvisionException as e : self . error ( f \"preprocess fetched task failed: { e } \" ) except Exception as e : self . exception ( e ) except grpc . aio . AioRpcError as e : self . error ( f \"gRPC error: can't connect with cluster manager, { e } \" ) self . _stop_event . set () stop ( self ) async \u00b6 stop worker Source code in fedvision/framework/cluster/worker.py async def stop ( self ): \"\"\" stop worker \"\"\" if self . _channel is not None : await self . _channel . close () self . _channel = None self . info ( f \"canceling unfinished asyncio tasks\" ) if self . _asyncio_task_collection is not None : for task in self . _asyncio_task_collection : if not task . done (): task . cancel () self . trace ( f \"canceled task { task } \" ) self . info ( f \"all unfinished asyncio tasks canceled\" )","title":"cluster"},{"location":"apis/cluster/#manager","text":"","title":"manager"},{"location":"apis/cluster/#fedvision.framework.cluster.manager","text":"","title":"manager"},{"location":"apis/cluster/#fedvision.framework.cluster.manager.ClusterManager","text":"","title":"ClusterManager"},{"location":"apis/cluster/#fedvision.framework.cluster.manager.ClusterManager.Enroll","text":"rpc server impl: process tasker enroll request Parameters: Name Type Description Default request REQ required context ServicerContext required Returns: Type Description AsyncGenerator[fedvision.framework.protobuf.cluster_pb2.REP, NoneType] Source code in fedvision/framework/cluster/manager.py async def Enroll ( self , request : cluster_pb2 . Enroll . REQ , context : grpc . aio . ServicerContext , ) -> AsyncGenerator [ cluster_pb2 . Enroll . REP , None ]: \"\"\" rpc server impl: process tasker enroll request Args: request: context: Returns: \"\"\" self . debug ( f \"cluster worker enroll request: { pretty_pb ( request ) } \" ) if self . has_worker ( request . worker_id ): yield cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . ALREADY_ENROLL ) return worker = self . add_worker ( request . worker_id , request . worker_ip , request . max_tasks , request . port_start , request . port_end , ) self . debug ( f \"cluster worker enroll success: worker: { request . worker_id } \" ) yield cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . ENROLL_SUCCESS ) while self . has_worker ( request . worker_id ): try : task = await worker . wait_next_task ( timeout = 5 ) except asyncio . TimeoutError : continue self . debug ( f \"task ready: job_id= { task . job_id } , task_id= { task . task_id } , task_type= { task . task_type } \" ) rep = cluster_pb2 . Enroll . REP ( status = cluster_pb2 . Enroll . TASK_READY , task = task ) self . debug ( f \"response task( { task . task_id } , { task . task_type } ) to worker { request . worker_id } \" ) yield rep self . remove_worker ( request . worker_id )","title":"Enroll()"},{"location":"apis/cluster/#fedvision.framework.cluster.manager.ClusterManager.TaskResourceRequire","text":"Missing associated documentation comment in .proto file. Source code in fedvision/framework/cluster/manager.py async def TaskResourceRequire ( self , request , context ): worker , endpoints = await self . dispatch ( resource = { \"endpoints\" : request . num_endpoints } ) if worker is None : return cluster_pb2 . TaskResourceRequire . REP ( status = cluster_pb2 . TaskResourceRequire . FAILED ) response = cluster_pb2 . TaskResourceRequire . REP ( status = cluster_pb2 . TaskResourceRequire . SUCCESS , worker_id = worker . worker_id ) for endpoint in endpoints : response . endpoints . append ( endpoint ) return response","title":"TaskResourceRequire()"},{"location":"apis/cluster/#fedvision.framework.cluster.manager.ClusterManager.TaskSubmit","text":"service for master: submit task to cluster Source code in fedvision/framework/cluster/manager.py async def TaskSubmit ( self , request : cluster_pb2 . TaskSubmit . REQ , context : grpc . aio . ServicerContext ) -> cluster_pb2 . TaskSubmit . REP : try : task = request . task if not task . assignee : worker , _ = await self . dispatch () await worker . put_task ( task = task ) else : await self . _alive_workers [ task . assignee ] . put_task ( task = task ) return cluster_pb2 . TaskSubmit . REP ( status = cluster_pb2 . TaskSubmit . SUCCESS ) except Exception as e : self . exception ( f \"handle task submit failed: { e } \" ) return cluster_pb2 . TaskSubmit . REP ( status = cluster_pb2 . TaskSubmit . FAILED )","title":"TaskSubmit()"},{"location":"apis/cluster/#fedvision.framework.cluster.manager.ClusterManager.UpdateTaskStatus","text":"process task status update request Parameters: Name Type Description Default request REQ required context ServicerContext required Returns: Type Description REP Source code in fedvision/framework/cluster/manager.py async def UpdateTaskStatus ( self , request : cluster_pb2 . UpdateStatus . REQ , context : grpc . aio . ServicerContext ) -> cluster_pb2 . UpdateStatus . REP : \"\"\" process task status update request Args: request: context: Returns: \"\"\" if request . worker_id not in self . _alive_workers : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . FAILED ) await self . _alive_workers [ request . worker_id ] . update_heartbeat () if not request . task_id : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . SUCCESS ) if not request . task_id not in self . _tasks_status : return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . FAILED ) self . debug ( f \"update task status: { request . task_id } to { request . task_status } \" ) self . _tasks_status [ request . task_id ] = request . task_status return cluster_pb2 . UpdateStatus . REP ( status = cluster_pb2 . UpdateStatus . SUCCESS )","title":"UpdateTaskStatus()"},{"location":"apis/cluster/#worker","text":"","title":"worker"},{"location":"apis/cluster/#fedvision.framework.cluster.worker","text":"","title":"worker"},{"location":"apis/cluster/#fedvision.framework.cluster.worker.ClusterWorker","text":"","title":"ClusterWorker"},{"location":"apis/cluster/#fedvision.framework.cluster.worker.ClusterWorker.start","text":"start worker enroll to manager start heartbeat loop start task exec loop process tasks Source code in fedvision/framework/cluster/worker.py async def start ( self ): \"\"\" start worker 1. enroll to manager 2. start heartbeat loop 3. start task exec loop 4. process tasks Returns: \"\"\" self . info ( f \"starting worker { self . _worker_id } \" ) self . info ( f \"staring grpc channel to cluster manager\" ) self . _channel = grpc . aio . insecure_channel ( self . _manager_address , options = [ ( \"grpc.max_send_message_length\" , 512 * 1024 * 1024 ), ( \"grpc.max_receive_message_length\" , 512 * 1024 * 1024 ), ], ) self . _stub = cluster_pb2_grpc . ClusterManagerStub ( self . _channel ) self . info ( f \"sending enroll request to cluster manager\" ) response_stream : AsyncIterable [ cluster_pb2 . Enroll . REP ] = self . _stub . Enroll ( cluster_pb2 . Enroll . REQ ( worker_id = self . _worker_id , worker_ip = self . _worker_ip , max_tasks = self . _max_tasks , port_start = self . _port_start , port_end = self . _port_end , ) ) first_response = True try : async for response in response_stream : if first_response : if response . status == cluster_pb2 . Enroll . ALREADY_ENROLL : raise FedvisionWorkerException ( f \"worker< { self . _worker_id } > already enrolled, use new name or remove it from manager\" ) if response . status != cluster_pb2 . Enroll . ENROLL_SUCCESS : raise FedvisionWorkerException ( f \"worker< { self . _worker_id } >enroll failed with unknown status: { response . status } \" ) self . info ( f \"worker< { self . _worker_id } >success enrolled to cluster manager\" ) async def _co_update_status (): while True : try : request = await asyncio . wait_for ( self . _task_status . get (), self . _heartbeat_interval ) except asyncio . TimeoutError : self . trace ( \"wait task status timeout. sending heartbeat request\" ) request = cluster_pb2 . UpdateStatus . REQ ( worker_id = self . _worker_id ) try : update_response = await self . _stub . UpdateTaskStatus ( request ) except grpc . aio . AioRpcError as _e : self . error ( f \"can't send heartbeat to manager, { _e } \" ) self . _stop_event . set () return if ( update_response . status != cluster_pb2 . UpdateStatus . SUCCESS ): self . error ( f \"update status failed, please check manager status\" ) self . info ( \"starting heartbeat loop\" ) self . _asyncio_task_collection = [ asyncio . create_task ( _co_update_status ()), ] self . info ( \"heartbeat loop started\" ) self . info ( f \"starting task execute loop\" ) self . _asyncio_task_collection . append ( asyncio . create_task ( self . _co_task_execute_loop ()) ) self . info ( f \"task execute loop started\" ) first_response = False continue # fetch tasks if response . status != cluster_pb2 . Enroll . TASK_READY : raise FedvisionWorkerException ( f \"expect status { cluster_pb2 . Enroll . TASK_READY } , got { response . status } \" ) self . trace_lazy ( f \"response < {{ response }} > got\" , response = lambda : pretty_pb ( response ) ) try : task_id = response . task . task_id task_type = response . task . task_type task_class = extensions . get_task_class ( task_type ) if task_class is None : self . error ( f \"task type { task_type } not found\" ) raise FedvisionExtensionException ( f \"task type { task_type } not found\" ) task = task_class . deserialize ( response . task ) await self . _task_queue . put ( task ) self . trace ( f \"put task in queue: task_id= { task_id } \" ) except FedvisionException as e : self . error ( f \"preprocess fetched task failed: { e } \" ) except Exception as e : self . exception ( e ) except grpc . aio . AioRpcError as e : self . error ( f \"gRPC error: can't connect with cluster manager, { e } \" ) self . _stop_event . set ()","title":"start()"},{"location":"apis/cluster/#fedvision.framework.cluster.worker.ClusterWorker.stop","text":"stop worker Source code in fedvision/framework/cluster/worker.py async def stop ( self ): \"\"\" stop worker \"\"\" if self . _channel is not None : await self . _channel . close () self . _channel = None self . info ( f \"canceling unfinished asyncio tasks\" ) if self . _asyncio_task_collection is not None : for task in self . _asyncio_task_collection : if not task . done (): task . cancel () self . trace ( f \"canceled task { task } \" ) self . info ( f \"all unfinished asyncio tasks canceled\" )","title":"stop()"},{"location":"apis/coordinator/","text":"Coordinator \u00b6 \u00b6 coordinator \u00b6 Coordinator \u00b6 __init__ ( self , port ) special \u00b6 init coordinator Parameters: Name Type Description Default port int coordinator serving port required Source code in fedvision/framework/coordinator/coordinator.py def __init__ ( self , port : int ): \"\"\" init coordinator Args: port: coordinator serving port \"\"\" self . _serving = True self . _enrolled : MutableMapping [ str , _TaskProviderForEnrolledParty ] = {} self . _proposals : MutableMapping [ str , _Proposal ] = {} self . _job_type_to_subscribes : MutableMapping [ str , MutableSet [ str ]] = {} self . _check_interval = 0.5 self . _count_id = 0 self . _grpc_port = port self . _grpc_server = None FetchTask ( self , request , context ) async \u00b6 handle task fetch gRPC request Parameters: Name Type Description Default request coordinator_pb2.FetchTask.REQ required context grpc.aio.ServicerContext required Returns: Type Description coordinator_pb2.Proposal.REP Source code in fedvision/framework/coordinator/coordinator.py async def FetchTask ( self , request : coordinator_pb2 . FetchTask . REQ , context : grpc . aio . ServicerContext ) -> coordinator_pb2 . Proposal . REP : \"\"\" handle task fetch gRPC request Args: request: context: Returns: \"\"\" if request . proposal_id not in self . _proposals : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . NOT_FOUND ) if request . party_id not in self . _enrolled : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . NOT_ALLOW ) proposal = self . _proposals [ request . proposal_id ] if proposal . open_period_finished . is_set (): return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . TIMEOUT ) proposal . add_responders ( request . party_id ) await proposal . open_period_finished . wait () if not proposal . goal_reached : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . CANCELED ) if request . party_id not in proposal . chosen : print ( request . party_id , proposal . chosen ) return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . RANDOM_OUT ) # accepted, finally! success_rep = coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . READY , task = proposal . chosen [ request . party_id ], ) return success_rep Leave ( self , request , context ) async \u00b6 Missing associated documentation comment in .proto file. Source code in fedvision/framework/coordinator/coordinator.py async def Leave ( self , request , context ): if request . party_id not in self . _enrolled : return coordinator_pb2 . Leave . REP ( status = coordinator_pb2 . Leave . NOT_FOUND ) self . _enrolled [ request . party_id ] . closed = True await self . _enrolled [ request . party_id ] . queue . join () self . _enrolled . __delitem__ ( request . party_id ) return coordinator_pb2 . Leave . REP ( status = coordinator_pb2 . Leave . SUCCESS ) Proposal ( self , request , context ) async \u00b6 handle job proposal gRPC request Parameters: Name Type Description Default request coordinator_pb2.Proposal.REQ required context grpc.aio.ServicerContext required Returns: Type Description coordinator_pb2.Proposal.REP Source code in fedvision/framework/coordinator/coordinator.py async def Proposal ( self , request : coordinator_pb2 . Proposal . REQ , context : grpc . aio . ServicerContext ) -> coordinator_pb2 . Proposal . REP : \"\"\" handle job proposal gRPC request Args: request: context: Returns: \"\"\" uid = self . _generate_proposal_id ( request . job_id ) proposal = _Proposal . from_pb ( uid = uid , pb = request ) self . _proposals [ uid ] = proposal if proposal . job_type not in self . _job_type_to_subscribes : self . info ( f \"job type { proposal . job_type } not in { self . _job_type_to_subscribes } , reject\" ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . REJECT ) if ( len ( self . _job_type_to_subscribes [ proposal . job_type ]) < proposal . minimum_acceptance ): self . info ( f \"not enough parties alive accept job type { proposal . job_type } ,\" f \" required { proposal . minimum_acceptance } , \" f \" { len ( self . _job_type_to_subscribes [ proposal . job_type ]) } alive\" ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . NOT_ENOUGH_SUBSCRIBERS ) # dispatch proposal for party_id in self . _job_type_to_subscribes [ proposal . job_type ]: await self . _enrolled [ party_id ] . queue . put ( proposal ) # sleep until timeout and then check if there are enough responders await asyncio . sleep ( request . proposal_wait_time ) if not proposal . has_enough_responders (): proposal . set_open_period_finished ( goal_reached = False ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . NOT_ENOUGH_RESPONDERS ) proposal . set_open_period_finished ( goal_reached = True ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . SUCCESS ) Subscribe ( self , request , context ) \u00b6 handle subscribe gRPC request, response job proposals in stream Parameters: Name Type Description Default request coordinator_pb2.Subscribe.REQ required context grpc.aio.ServicerContext required Returns: Type Description AsyncGenerator[coordinator_pb2.Subscribe.REP, None] Source code in fedvision/framework/coordinator/coordinator.py async def Subscribe ( self , request : coordinator_pb2 . Subscribe . REQ , context : grpc . aio . ServicerContext ) -> AsyncGenerator [ coordinator_pb2 . Subscribe . REP , None ]: \"\"\" handle subscribe gRPC request, response job proposals in stream Args: request: context: Returns: \"\"\" if request . party_id in self . _enrolled : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . DUPLICATE_ENROLL ) return if not self . _serving : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . NOT_SERVING ) return task_provider = _TaskProviderForEnrolledParty () self . _enrolled [ request . party_id ] = task_provider for job_type in request . job_types : self . _job_type_to_subscribes . setdefault ( job_type , set ()) . add ( request . party_id ) while True : if task_provider . closed : break try : # make stop subscribe passable, check status regularly proposal = await asyncio . wait_for ( task_provider . queue . get (), timeout = self . _check_interval ) except asyncio . TimeoutError : # not receive proposal task for a while, maybe: # 1. just no new proposal # 2. flag has changed to false and no new proposal will in-queue continue else : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . SUCCESS , proposal_id = proposal . uid , job_type = proposal . job_type , ) task_provider . queue . task_done () # clean proposals while not task_provider . queue . empty (): await task_provider . queue . get () task_provider . queue . task_done ()","title":"coordinator"},{"location":"apis/coordinator/#coordinator","text":"","title":"Coordinator"},{"location":"apis/coordinator/#fedvision.framework.coordinator","text":"","title":"fedvision.framework.coordinator"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator","text":"","title":"coordinator"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator","text":"","title":"Coordinator"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator.__init__","text":"init coordinator Parameters: Name Type Description Default port int coordinator serving port required Source code in fedvision/framework/coordinator/coordinator.py def __init__ ( self , port : int ): \"\"\" init coordinator Args: port: coordinator serving port \"\"\" self . _serving = True self . _enrolled : MutableMapping [ str , _TaskProviderForEnrolledParty ] = {} self . _proposals : MutableMapping [ str , _Proposal ] = {} self . _job_type_to_subscribes : MutableMapping [ str , MutableSet [ str ]] = {} self . _check_interval = 0.5 self . _count_id = 0 self . _grpc_port = port self . _grpc_server = None","title":"__init__()"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator.FetchTask","text":"handle task fetch gRPC request Parameters: Name Type Description Default request coordinator_pb2.FetchTask.REQ required context grpc.aio.ServicerContext required Returns: Type Description coordinator_pb2.Proposal.REP Source code in fedvision/framework/coordinator/coordinator.py async def FetchTask ( self , request : coordinator_pb2 . FetchTask . REQ , context : grpc . aio . ServicerContext ) -> coordinator_pb2 . Proposal . REP : \"\"\" handle task fetch gRPC request Args: request: context: Returns: \"\"\" if request . proposal_id not in self . _proposals : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . NOT_FOUND ) if request . party_id not in self . _enrolled : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . NOT_ALLOW ) proposal = self . _proposals [ request . proposal_id ] if proposal . open_period_finished . is_set (): return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . TIMEOUT ) proposal . add_responders ( request . party_id ) await proposal . open_period_finished . wait () if not proposal . goal_reached : return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . CANCELED ) if request . party_id not in proposal . chosen : print ( request . party_id , proposal . chosen ) return coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . RANDOM_OUT ) # accepted, finally! success_rep = coordinator_pb2 . FetchTask . REP ( status = coordinator_pb2 . FetchTask . READY , task = proposal . chosen [ request . party_id ], ) return success_rep","title":"FetchTask()"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator.Leave","text":"Missing associated documentation comment in .proto file. Source code in fedvision/framework/coordinator/coordinator.py async def Leave ( self , request , context ): if request . party_id not in self . _enrolled : return coordinator_pb2 . Leave . REP ( status = coordinator_pb2 . Leave . NOT_FOUND ) self . _enrolled [ request . party_id ] . closed = True await self . _enrolled [ request . party_id ] . queue . join () self . _enrolled . __delitem__ ( request . party_id ) return coordinator_pb2 . Leave . REP ( status = coordinator_pb2 . Leave . SUCCESS )","title":"Leave()"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator.Proposal","text":"handle job proposal gRPC request Parameters: Name Type Description Default request coordinator_pb2.Proposal.REQ required context grpc.aio.ServicerContext required Returns: Type Description coordinator_pb2.Proposal.REP Source code in fedvision/framework/coordinator/coordinator.py async def Proposal ( self , request : coordinator_pb2 . Proposal . REQ , context : grpc . aio . ServicerContext ) -> coordinator_pb2 . Proposal . REP : \"\"\" handle job proposal gRPC request Args: request: context: Returns: \"\"\" uid = self . _generate_proposal_id ( request . job_id ) proposal = _Proposal . from_pb ( uid = uid , pb = request ) self . _proposals [ uid ] = proposal if proposal . job_type not in self . _job_type_to_subscribes : self . info ( f \"job type { proposal . job_type } not in { self . _job_type_to_subscribes } , reject\" ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . REJECT ) if ( len ( self . _job_type_to_subscribes [ proposal . job_type ]) < proposal . minimum_acceptance ): self . info ( f \"not enough parties alive accept job type { proposal . job_type } ,\" f \" required { proposal . minimum_acceptance } , \" f \" { len ( self . _job_type_to_subscribes [ proposal . job_type ]) } alive\" ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . NOT_ENOUGH_SUBSCRIBERS ) # dispatch proposal for party_id in self . _job_type_to_subscribes [ proposal . job_type ]: await self . _enrolled [ party_id ] . queue . put ( proposal ) # sleep until timeout and then check if there are enough responders await asyncio . sleep ( request . proposal_wait_time ) if not proposal . has_enough_responders (): proposal . set_open_period_finished ( goal_reached = False ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . NOT_ENOUGH_RESPONDERS ) proposal . set_open_period_finished ( goal_reached = True ) return coordinator_pb2 . Proposal . REP ( status = coordinator_pb2 . Proposal . SUCCESS )","title":"Proposal()"},{"location":"apis/coordinator/#fedvision.framework.coordinator.coordinator.Coordinator.Subscribe","text":"handle subscribe gRPC request, response job proposals in stream Parameters: Name Type Description Default request coordinator_pb2.Subscribe.REQ required context grpc.aio.ServicerContext required Returns: Type Description AsyncGenerator[coordinator_pb2.Subscribe.REP, None] Source code in fedvision/framework/coordinator/coordinator.py async def Subscribe ( self , request : coordinator_pb2 . Subscribe . REQ , context : grpc . aio . ServicerContext ) -> AsyncGenerator [ coordinator_pb2 . Subscribe . REP , None ]: \"\"\" handle subscribe gRPC request, response job proposals in stream Args: request: context: Returns: \"\"\" if request . party_id in self . _enrolled : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . DUPLICATE_ENROLL ) return if not self . _serving : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . NOT_SERVING ) return task_provider = _TaskProviderForEnrolledParty () self . _enrolled [ request . party_id ] = task_provider for job_type in request . job_types : self . _job_type_to_subscribes . setdefault ( job_type , set ()) . add ( request . party_id ) while True : if task_provider . closed : break try : # make stop subscribe passable, check status regularly proposal = await asyncio . wait_for ( task_provider . queue . get (), timeout = self . _check_interval ) except asyncio . TimeoutError : # not receive proposal task for a while, maybe: # 1. just no new proposal # 2. flag has changed to false and no new proposal will in-queue continue else : yield coordinator_pb2 . Subscribe . REP ( status = coordinator_pb2 . Subscribe . SUCCESS , proposal_id = proposal . uid , job_type = proposal . job_type , ) task_provider . queue . task_done () # clean proposals while not task_provider . queue . empty (): await task_provider . queue . get () task_provider . queue . task_done ()","title":"Subscribe()"},{"location":"apis/master/","text":"Coordinator \u00b6 \u00b6 Master \u00b6 __init__ ( self , party_id , coordinator_address , cluster_address , rest_port , rest_host = None ) special \u00b6 init master Parameters: Name Type Description Default party_id str required coordinator_address str required rest_port int required rest_host str None Source code in fedvision/framework/master/master.py def __init__ ( self , party_id : str , coordinator_address : str , cluster_address : str , rest_port : int , rest_host : str = None , ): \"\"\" init master Args: party_id: coordinator_address: rest_port: rest_host: \"\"\" self . shared_status = _SharedStatus ( party_id = party_id ) self . _coordinator = CoordinatorConnect ( shared_status = self . shared_status , address = coordinator_address ) self . _rest_site = RESTService ( shared_status = self . shared_status , port = rest_port , host = rest_host ) self . _cluster = ClusterManagerConnect ( shared_status = self . shared_status , address = cluster_address ) start ( self ) async \u00b6 start master: 1. cluster manager to process tasks 2. restful service to handler request from user 3. coordinator to connect to `the world` Source code in fedvision/framework/master/master.py async def start ( self ): \"\"\" start master: 1. cluster manager to process tasks 2. restful service to handler request from user 3. coordinator to connect to `the world` \"\"\" # connect to cluster await self . _cluster . start_cluster_channel () while True : try : await asyncio . wait_for ( self . _cluster . cluster_channel_ready (), 5 ) except asyncio . TimeoutError : self . warning ( f \"cluster channel not ready, retry in 5 seconds\" ) else : self . info ( f \"cluster channel ready!\" ) break asyncio . create_task ( self . _cluster . submit_tasks_to_cluster ()) # start rest site await self . _rest_site . start_rest_site () # connect to coordinator await self . _coordinator . start_coordinator_channel () while True : try : await asyncio . wait_for ( self . _coordinator . coordinator_channel_ready (), 5 ) except asyncio . TimeoutError : self . warning ( f \"coordinator channel not ready, retry in 5 seconds\" ) else : self . info ( f \"coordinator channel ready!\" ) break asyncio . create_task ( self . _coordinator . subscribe ()) # job process loop: # 1. get job from rest site # 2. make proposal to coordinator # 3. send task to cluster by put it into a queue asyncio . create_task ( self . _submitted_job_handler ()) stop ( self ) async \u00b6 stop master Source code in fedvision/framework/master/master.py async def stop ( self ): \"\"\" stop master \"\"\" await self . _coordinator . stop_coordinator_channel ( grace = 1 ) await self . _rest_site . stop_rest_site () await self . _cluster . stop_cluster_channel ( grace = 1 ) ProposalAcceptRule \u00b6 __eq__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __eq__ ( self , other ): if other . __class__ is not self . __class__ : return NotImplemented return ( self . shared_status , ) == ( other . shared_status , ) __ge__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __ge__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) >= attrs_to_tuple ( other ) return NotImplemented __gt__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __gt__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) > attrs_to_tuple ( other ) return NotImplemented __init__ ( self , shared_status ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __init__ ( self , shared_status ): self . shared_status = shared_status __le__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __le__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) <= attrs_to_tuple ( other ) return NotImplemented __lt__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __lt__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) < attrs_to_tuple ( other ) return NotImplemented __ne__ ( self , other ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __ne__ ( self , other ): \"\"\" Check equality and either forward a NotImplemented or return the result negated. \"\"\" result = self . __eq__ ( other ) if result is NotImplemented : return NotImplemented return not result __repr__ ( self ) special \u00b6 Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __repr__ ( self ): \"\"\" Automatically created by attrs. \"\"\" try : working_set = _already_repring . working_set except AttributeError : working_set = set () _already_repring . working_set = working_set if id ( self ) in working_set : return \"...\" real_cls = self . __class__ if ns is None : qualname = getattr ( real_cls , \"__qualname__\" , None ) if qualname is not None : class_name = qualname . rsplit ( \">.\" , 1 )[ - 1 ] else : class_name = real_cls . __name__ else : class_name = ns + \".\" + real_cls . __name__ # Since 'self' remains on the stack (i.e.: strongly referenced) for the # duration of this call, it's safe to depend on id(...) stability, and # not need to track the instance and therefore worry about properties # like weakref- or hash-ability. working_set . add ( id ( self )) try : result = [ class_name , \"(\" ] first = True for name , attr_repr in attr_names_with_reprs : if first : first = False else : result . append ( \", \" ) result . extend ( ( name , \"=\" , attr_repr ( getattr ( self , name , NOTHING ))) ) return \"\" . join ( result ) + \")\" finally : working_set . remove ( id ( self )) RESTService \u00b6 start_rest_site ( self ) async \u00b6 start web service non-blocked Source code in fedvision/framework/master/master.py async def start_rest_site ( self ): \"\"\" start web service non-blocked \"\"\" self . info ( f \"starting restful services at { ':' if self . host is None else self . host } : { self . port } \" ) app = web . Application () app . add_routes ( self . _register_routes ()) runner = web . AppRunner ( app , access_log = self . get_logger ()) await runner . setup () self . _site = web . TCPSite ( runner = runner , host = self . host , port = self . port ) await self . _site . start () self . info ( f \"restful services started at { ':' if self . host is None else self . host } : { self . port } \" ) stop_rest_site ( self ) async \u00b6 stop web service Source code in fedvision/framework/master/master.py async def stop_rest_site ( self ): \"\"\" stop web service \"\"\" if self . _site is not None : await self . _site . stop ()","title":"master"},{"location":"apis/master/#coordinator","text":"","title":"Coordinator"},{"location":"apis/master/#fedvision.framework.master.master","text":"","title":"fedvision.framework.master.master"},{"location":"apis/master/#fedvision.framework.master.master.Master","text":"","title":"Master"},{"location":"apis/master/#fedvision.framework.master.master.Master.__init__","text":"init master Parameters: Name Type Description Default party_id str required coordinator_address str required rest_port int required rest_host str None Source code in fedvision/framework/master/master.py def __init__ ( self , party_id : str , coordinator_address : str , cluster_address : str , rest_port : int , rest_host : str = None , ): \"\"\" init master Args: party_id: coordinator_address: rest_port: rest_host: \"\"\" self . shared_status = _SharedStatus ( party_id = party_id ) self . _coordinator = CoordinatorConnect ( shared_status = self . shared_status , address = coordinator_address ) self . _rest_site = RESTService ( shared_status = self . shared_status , port = rest_port , host = rest_host ) self . _cluster = ClusterManagerConnect ( shared_status = self . shared_status , address = cluster_address )","title":"__init__()"},{"location":"apis/master/#fedvision.framework.master.master.Master.start","text":"start master: 1. cluster manager to process tasks 2. restful service to handler request from user 3. coordinator to connect to `the world` Source code in fedvision/framework/master/master.py async def start ( self ): \"\"\" start master: 1. cluster manager to process tasks 2. restful service to handler request from user 3. coordinator to connect to `the world` \"\"\" # connect to cluster await self . _cluster . start_cluster_channel () while True : try : await asyncio . wait_for ( self . _cluster . cluster_channel_ready (), 5 ) except asyncio . TimeoutError : self . warning ( f \"cluster channel not ready, retry in 5 seconds\" ) else : self . info ( f \"cluster channel ready!\" ) break asyncio . create_task ( self . _cluster . submit_tasks_to_cluster ()) # start rest site await self . _rest_site . start_rest_site () # connect to coordinator await self . _coordinator . start_coordinator_channel () while True : try : await asyncio . wait_for ( self . _coordinator . coordinator_channel_ready (), 5 ) except asyncio . TimeoutError : self . warning ( f \"coordinator channel not ready, retry in 5 seconds\" ) else : self . info ( f \"coordinator channel ready!\" ) break asyncio . create_task ( self . _coordinator . subscribe ()) # job process loop: # 1. get job from rest site # 2. make proposal to coordinator # 3. send task to cluster by put it into a queue asyncio . create_task ( self . _submitted_job_handler ())","title":"start()"},{"location":"apis/master/#fedvision.framework.master.master.Master.stop","text":"stop master Source code in fedvision/framework/master/master.py async def stop ( self ): \"\"\" stop master \"\"\" await self . _coordinator . stop_coordinator_channel ( grace = 1 ) await self . _rest_site . stop_rest_site () await self . _cluster . stop_cluster_channel ( grace = 1 )","title":"stop()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule","text":"","title":"ProposalAcceptRule"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__eq__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __eq__ ( self , other ): if other . __class__ is not self . __class__ : return NotImplemented return ( self . shared_status , ) == ( other . shared_status , )","title":"__eq__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__ge__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __ge__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) >= attrs_to_tuple ( other ) return NotImplemented","title":"__ge__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__gt__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __gt__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) > attrs_to_tuple ( other ) return NotImplemented","title":"__gt__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__init__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __init__ ( self , shared_status ): self . shared_status = shared_status","title":"__init__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__le__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __le__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) <= attrs_to_tuple ( other ) return NotImplemented","title":"__le__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__lt__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __lt__ ( self , other ): \"\"\" Automatically created by attrs. \"\"\" if other . __class__ is self . __class__ : return attrs_to_tuple ( self ) < attrs_to_tuple ( other ) return NotImplemented","title":"__lt__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__ne__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __ne__ ( self , other ): \"\"\" Check equality and either forward a NotImplemented or return the result negated. \"\"\" result = self . __eq__ ( other ) if result is NotImplemented : return NotImplemented return not result","title":"__ne__()"},{"location":"apis/master/#fedvision.framework.master.master.ProposalAcceptRule.__repr__","text":"Method generated by attrs for class ProposalAcceptRule. Source code in fedvision/framework/master/master.py def __repr__ ( self ): \"\"\" Automatically created by attrs. \"\"\" try : working_set = _already_repring . working_set except AttributeError : working_set = set () _already_repring . working_set = working_set if id ( self ) in working_set : return \"...\" real_cls = self . __class__ if ns is None : qualname = getattr ( real_cls , \"__qualname__\" , None ) if qualname is not None : class_name = qualname . rsplit ( \">.\" , 1 )[ - 1 ] else : class_name = real_cls . __name__ else : class_name = ns + \".\" + real_cls . __name__ # Since 'self' remains on the stack (i.e.: strongly referenced) for the # duration of this call, it's safe to depend on id(...) stability, and # not need to track the instance and therefore worry about properties # like weakref- or hash-ability. working_set . add ( id ( self )) try : result = [ class_name , \"(\" ] first = True for name , attr_repr in attr_names_with_reprs : if first : first = False else : result . append ( \", \" ) result . extend ( ( name , \"=\" , attr_repr ( getattr ( self , name , NOTHING ))) ) return \"\" . join ( result ) + \")\" finally : working_set . remove ( id ( self ))","title":"__repr__()"},{"location":"apis/master/#fedvision.framework.master.master.RESTService","text":"","title":"RESTService"},{"location":"apis/master/#fedvision.framework.master.master.RESTService.start_rest_site","text":"start web service non-blocked Source code in fedvision/framework/master/master.py async def start_rest_site ( self ): \"\"\" start web service non-blocked \"\"\" self . info ( f \"starting restful services at { ':' if self . host is None else self . host } : { self . port } \" ) app = web . Application () app . add_routes ( self . _register_routes ()) runner = web . AppRunner ( app , access_log = self . get_logger ()) await runner . setup () self . _site = web . TCPSite ( runner = runner , host = self . host , port = self . port ) await self . _site . start () self . info ( f \"restful services started at { ':' if self . host is None else self . host } : { self . port } \" )","title":"start_rest_site()"},{"location":"apis/master/#fedvision.framework.master.master.RESTService.stop_rest_site","text":"stop web service Source code in fedvision/framework/master/master.py async def stop_rest_site ( self ): \"\"\" stop web service \"\"\" if self . _site is not None : await self . _site . stop ()","title":"stop_rest_site()"},{"location":"apis/proto/","text":"Protocol Documentation \u00b6 Table of Contents \u00b6 fedvision/paddle_fl/protobuf/scheduler.proto Init Init.REP Init.REQ WorkerFinish WorkerFinish.REP WorkerFinish.REQ WorkerJoin WorkerJoin.REP WorkerJoin.REQ Init.Status WorkerFinish.Status WorkerJoin.Status Scheduler fedvision/framework/protobuf/job.proto Task fedvision/paddle_fl/protobuf/fl_job.proto PaddleFLAggregatorTask PaddleFLWorkerTask fedvision/framework/protobuf/coordinator.proto FetchTask FetchTask.REP FetchTask.REQ Leave Leave.REP Leave.REQ Proposal Proposal.REP Proposal.REQ Subscribe Subscribe.REP Subscribe.REQ FetchTask.Status Leave.Status Proposal.Status Subscribe.Status Coordinator fedvision/framework/protobuf/cluster.proto Enroll Enroll.REP Enroll.REQ TaskResourceRequire TaskResourceRequire.REP TaskResourceRequire.REQ TaskSubmit TaskSubmit.REP TaskSubmit.REQ UpdateStatus UpdateStatus.REP UpdateStatus.REQ Enroll.Status TaskResourceRequire.Status TaskSubmit.Status UpdateStatus.Status UpdateStatus.TaskStatus ClusterManager Scalar Value Types Top fedvision/paddle_fl/protobuf/scheduler.proto \u00b6 Init \u00b6 Init.REP \u00b6 Field Type Label Description status Init.Status Init.REQ \u00b6 Field Type Label Description name string WorkerFinish \u00b6 WorkerFinish.REP \u00b6 Field Type Label Description status WorkerFinish.Status WorkerFinish.REQ \u00b6 Field Type Label Description name string WorkerJoin \u00b6 WorkerJoin.REP \u00b6 Field Type Label Description status WorkerJoin.Status WorkerJoin.REQ \u00b6 Field Type Label Description name string step uint32 Init.Status \u00b6 Name Number Description REJECT 0 INIT 1 WorkerFinish.Status \u00b6 Name Number Description REJECT 0 DONE 1 WorkerJoin.Status \u00b6 Name Number Description REJECT 0 NOT_SELECTED 1 ACCEPT 2 Scheduler \u00b6 Method Name Request Type Response Type Description Init Init.REQ Init.REP WorkerJoin WorkerJoin.REQ WorkerJoin.REP WorkerFinish WorkerFinish.REQ WorkerFinish.REP Top fedvision/framework/protobuf/job.proto \u00b6 Task \u00b6 Field Type Label Description job_id string task_id string task_type string task google.protobuf.Any assignee string Top fedvision/paddle_fl/protobuf/fl_job.proto \u00b6 PaddleFLAggregatorTask \u00b6 Field Type Label Description scheduler_ep string main_program bytes startup_program bytes config_string string PaddleFLWorkerTask \u00b6 Field Type Label Description scheduler_ep string trainer_id uint32 trainer_ep string entrypoint string main_program bytes startup_program bytes send_program bytes recv_program bytes feed_names bytes target_names bytes strategy bytes feeds bytes config_string string algorithm_config_string string Top fedvision/framework/protobuf/coordinator.proto \u00b6 FetchTask \u00b6 FetchTask.REP \u00b6 Field Type Label Description status FetchTask.Status task fedvision.framework.Task FetchTask.REQ \u00b6 Field Type Label Description party_id string proposal_id string Leave \u00b6 Leave.REP \u00b6 Field Type Label Description status Leave.Status Leave.REQ \u00b6 Field Type Label Description party_id string Proposal \u00b6 Proposal.REP \u00b6 Field Type Label Description status Proposal.Status Proposal.REQ \u00b6 Field Type Label Description job_id string job_type string tasks fedvision.framework.Task repeated proposal_wait_time uint32 minimum_acceptance uint32 maximum_acceptance uint32 Subscribe \u00b6 Subscribe.REP \u00b6 Field Type Label Description status Subscribe.Status proposal_id string job_type string Subscribe.REQ \u00b6 Field Type Label Description party_id string job_types string repeated credential string preserve FetchTask.Status \u00b6 Name Number Description NOT_FOUND 0 NOT_ALLOW 1 TIMEOUT 2 CANCELED 3 RANDOM_OUT 4 READY 5 Leave.Status \u00b6 Name Number Description NOT_FOUND 0 SUCCESS 1 Proposal.Status \u00b6 Name Number Description UNKNOWN 0 SUCCESS 1 NOT_ENOUGH_RESPONDERS 2 NOT_ENOUGH_SUBSCRIBERS 3 REJECT 4 Subscribe.Status \u00b6 Name Number Description DUPLICATE_ENROLL 0 NOT_SERVING 1 SUCCESS 2 Coordinator \u00b6 Method Name Request Type Response Type Description Subscribe Subscribe.REQ Subscribe.REP stream Proposal Proposal.REQ Proposal.REP FetchTask FetchTask.REQ FetchTask.REP Leave Leave.REQ Leave.REP Top fedvision/framework/protobuf/cluster.proto \u00b6 Enroll \u00b6 Enroll.REP \u00b6 Field Type Label Description status Enroll.Status task fedvision.framework.Task Enroll.REQ \u00b6 Field Type Label Description worker_id string worker_ip string max_tasks int32 port_start int32 port_end int32 TaskResourceRequire \u00b6 TaskResourceRequire.REP \u00b6 Field Type Label Description status TaskResourceRequire.Status worker_id string endpoints string repeated TaskResourceRequire.REQ \u00b6 Field Type Label Description num_endpoints int32 TaskSubmit \u00b6 TaskSubmit.REP \u00b6 Field Type Label Description status TaskSubmit.Status TaskSubmit.REQ \u00b6 Field Type Label Description task fedvision.framework.Task UpdateStatus \u00b6 UpdateStatus.REP \u00b6 Field Type Label Description status UpdateStatus.Status UpdateStatus.REQ \u00b6 Field Type Label Description worker_id string job_id string task_id string task_status UpdateStatus.TaskStatus exception_id string exception string exec_result google.protobuf.Any Enroll.Status \u00b6 Name Number Description UNKNOWN 0 ENROLL_SUCCESS 1 ALREADY_ENROLL 2 TASK_READY 3 TaskResourceRequire.Status \u00b6 Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2 TaskSubmit.Status \u00b6 Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2 UpdateStatus.Status \u00b6 Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2 UpdateStatus.TaskStatus \u00b6 Name Number Description TASK_UNKNOWN 0 TASK_CANCEL 1 TASK_EXCEPTION 2 TASK_FINISH 3 ClusterManager \u00b6 service in cluster manager called by worker Method Name Request Type Response Type Description Enroll Enroll.REQ Enroll.REP stream service for worker: enroll and fetch tasks UpdateTaskStatus UpdateStatus.REQ UpdateStatus.REP service for worker: update status or heartbeat TaskSubmit TaskSubmit.REQ TaskSubmit.REP service for master: submit task to cluster TaskResourceRequire TaskResourceRequire.REQ TaskResourceRequire.REP Scalar Value Types \u00b6 .proto Type Notes C++ Java Python Go C# PHP Ruby double double double float float64 double float Float float float float float float32 float float Float int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required) int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required) uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required) sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required) sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required) fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required) sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum bool bool boolean boolean bool bool boolean TrueClass/FalseClass string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8) bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)","title":"proto buffer"},{"location":"apis/proto/#protocol-documentation","text":"","title":"Protocol Documentation"},{"location":"apis/proto/#table-of-contents","text":"fedvision/paddle_fl/protobuf/scheduler.proto Init Init.REP Init.REQ WorkerFinish WorkerFinish.REP WorkerFinish.REQ WorkerJoin WorkerJoin.REP WorkerJoin.REQ Init.Status WorkerFinish.Status WorkerJoin.Status Scheduler fedvision/framework/protobuf/job.proto Task fedvision/paddle_fl/protobuf/fl_job.proto PaddleFLAggregatorTask PaddleFLWorkerTask fedvision/framework/protobuf/coordinator.proto FetchTask FetchTask.REP FetchTask.REQ Leave Leave.REP Leave.REQ Proposal Proposal.REP Proposal.REQ Subscribe Subscribe.REP Subscribe.REQ FetchTask.Status Leave.Status Proposal.Status Subscribe.Status Coordinator fedvision/framework/protobuf/cluster.proto Enroll Enroll.REP Enroll.REQ TaskResourceRequire TaskResourceRequire.REP TaskResourceRequire.REQ TaskSubmit TaskSubmit.REP TaskSubmit.REQ UpdateStatus UpdateStatus.REP UpdateStatus.REQ Enroll.Status TaskResourceRequire.Status TaskSubmit.Status UpdateStatus.Status UpdateStatus.TaskStatus ClusterManager Scalar Value Types Top","title":"Table of Contents"},{"location":"apis/proto/#fedvisionpaddle_flprotobufschedulerproto","text":"","title":"fedvision/paddle_fl/protobuf/scheduler.proto"},{"location":"apis/proto/#init","text":"","title":"Init"},{"location":"apis/proto/#initrep","text":"Field Type Label Description status Init.Status","title":"Init.REP"},{"location":"apis/proto/#initreq","text":"Field Type Label Description name string","title":"Init.REQ"},{"location":"apis/proto/#workerfinish","text":"","title":"WorkerFinish"},{"location":"apis/proto/#workerfinishrep","text":"Field Type Label Description status WorkerFinish.Status","title":"WorkerFinish.REP"},{"location":"apis/proto/#workerfinishreq","text":"Field Type Label Description name string","title":"WorkerFinish.REQ"},{"location":"apis/proto/#workerjoin","text":"","title":"WorkerJoin"},{"location":"apis/proto/#workerjoinrep","text":"Field Type Label Description status WorkerJoin.Status","title":"WorkerJoin.REP"},{"location":"apis/proto/#workerjoinreq","text":"Field Type Label Description name string step uint32","title":"WorkerJoin.REQ"},{"location":"apis/proto/#initstatus","text":"Name Number Description REJECT 0 INIT 1","title":"Init.Status"},{"location":"apis/proto/#workerfinishstatus","text":"Name Number Description REJECT 0 DONE 1","title":"WorkerFinish.Status"},{"location":"apis/proto/#workerjoinstatus","text":"Name Number Description REJECT 0 NOT_SELECTED 1 ACCEPT 2","title":"WorkerJoin.Status"},{"location":"apis/proto/#scheduler","text":"Method Name Request Type Response Type Description Init Init.REQ Init.REP WorkerJoin WorkerJoin.REQ WorkerJoin.REP WorkerFinish WorkerFinish.REQ WorkerFinish.REP Top","title":"Scheduler"},{"location":"apis/proto/#fedvisionframeworkprotobufjobproto","text":"","title":"fedvision/framework/protobuf/job.proto"},{"location":"apis/proto/#task","text":"Field Type Label Description job_id string task_id string task_type string task google.protobuf.Any assignee string Top","title":"Task"},{"location":"apis/proto/#fedvisionpaddle_flprotobuffl_jobproto","text":"","title":"fedvision/paddle_fl/protobuf/fl_job.proto"},{"location":"apis/proto/#paddleflaggregatortask","text":"Field Type Label Description scheduler_ep string main_program bytes startup_program bytes config_string string","title":"PaddleFLAggregatorTask"},{"location":"apis/proto/#paddleflworkertask","text":"Field Type Label Description scheduler_ep string trainer_id uint32 trainer_ep string entrypoint string main_program bytes startup_program bytes send_program bytes recv_program bytes feed_names bytes target_names bytes strategy bytes feeds bytes config_string string algorithm_config_string string Top","title":"PaddleFLWorkerTask"},{"location":"apis/proto/#fedvisionframeworkprotobufcoordinatorproto","text":"","title":"fedvision/framework/protobuf/coordinator.proto"},{"location":"apis/proto/#fetchtask","text":"","title":"FetchTask"},{"location":"apis/proto/#fetchtaskrep","text":"Field Type Label Description status FetchTask.Status task fedvision.framework.Task","title":"FetchTask.REP"},{"location":"apis/proto/#fetchtaskreq","text":"Field Type Label Description party_id string proposal_id string","title":"FetchTask.REQ"},{"location":"apis/proto/#leave","text":"","title":"Leave"},{"location":"apis/proto/#leaverep","text":"Field Type Label Description status Leave.Status","title":"Leave.REP"},{"location":"apis/proto/#leavereq","text":"Field Type Label Description party_id string","title":"Leave.REQ"},{"location":"apis/proto/#proposal","text":"","title":"Proposal"},{"location":"apis/proto/#proposalrep","text":"Field Type Label Description status Proposal.Status","title":"Proposal.REP"},{"location":"apis/proto/#proposalreq","text":"Field Type Label Description job_id string job_type string tasks fedvision.framework.Task repeated proposal_wait_time uint32 minimum_acceptance uint32 maximum_acceptance uint32","title":"Proposal.REQ"},{"location":"apis/proto/#subscribe","text":"","title":"Subscribe"},{"location":"apis/proto/#subscriberep","text":"Field Type Label Description status Subscribe.Status proposal_id string job_type string","title":"Subscribe.REP"},{"location":"apis/proto/#subscribereq","text":"Field Type Label Description party_id string job_types string repeated credential string preserve","title":"Subscribe.REQ"},{"location":"apis/proto/#fetchtaskstatus","text":"Name Number Description NOT_FOUND 0 NOT_ALLOW 1 TIMEOUT 2 CANCELED 3 RANDOM_OUT 4 READY 5","title":"FetchTask.Status"},{"location":"apis/proto/#leavestatus","text":"Name Number Description NOT_FOUND 0 SUCCESS 1","title":"Leave.Status"},{"location":"apis/proto/#proposalstatus","text":"Name Number Description UNKNOWN 0 SUCCESS 1 NOT_ENOUGH_RESPONDERS 2 NOT_ENOUGH_SUBSCRIBERS 3 REJECT 4","title":"Proposal.Status"},{"location":"apis/proto/#subscribestatus","text":"Name Number Description DUPLICATE_ENROLL 0 NOT_SERVING 1 SUCCESS 2","title":"Subscribe.Status"},{"location":"apis/proto/#coordinator","text":"Method Name Request Type Response Type Description Subscribe Subscribe.REQ Subscribe.REP stream Proposal Proposal.REQ Proposal.REP FetchTask FetchTask.REQ FetchTask.REP Leave Leave.REQ Leave.REP Top","title":"Coordinator"},{"location":"apis/proto/#fedvisionframeworkprotobufclusterproto","text":"","title":"fedvision/framework/protobuf/cluster.proto"},{"location":"apis/proto/#enroll","text":"","title":"Enroll"},{"location":"apis/proto/#enrollrep","text":"Field Type Label Description status Enroll.Status task fedvision.framework.Task","title":"Enroll.REP"},{"location":"apis/proto/#enrollreq","text":"Field Type Label Description worker_id string worker_ip string max_tasks int32 port_start int32 port_end int32","title":"Enroll.REQ"},{"location":"apis/proto/#taskresourcerequire","text":"","title":"TaskResourceRequire"},{"location":"apis/proto/#taskresourcerequirerep","text":"Field Type Label Description status TaskResourceRequire.Status worker_id string endpoints string repeated","title":"TaskResourceRequire.REP"},{"location":"apis/proto/#taskresourcerequirereq","text":"Field Type Label Description num_endpoints int32","title":"TaskResourceRequire.REQ"},{"location":"apis/proto/#tasksubmit","text":"","title":"TaskSubmit"},{"location":"apis/proto/#tasksubmitrep","text":"Field Type Label Description status TaskSubmit.Status","title":"TaskSubmit.REP"},{"location":"apis/proto/#tasksubmitreq","text":"Field Type Label Description task fedvision.framework.Task","title":"TaskSubmit.REQ"},{"location":"apis/proto/#updatestatus","text":"","title":"UpdateStatus"},{"location":"apis/proto/#updatestatusrep","text":"Field Type Label Description status UpdateStatus.Status","title":"UpdateStatus.REP"},{"location":"apis/proto/#updatestatusreq","text":"Field Type Label Description worker_id string job_id string task_id string task_status UpdateStatus.TaskStatus exception_id string exception string exec_result google.protobuf.Any","title":"UpdateStatus.REQ"},{"location":"apis/proto/#enrollstatus","text":"Name Number Description UNKNOWN 0 ENROLL_SUCCESS 1 ALREADY_ENROLL 2 TASK_READY 3","title":"Enroll.Status"},{"location":"apis/proto/#taskresourcerequirestatus","text":"Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2","title":"TaskResourceRequire.Status"},{"location":"apis/proto/#tasksubmitstatus","text":"Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2","title":"TaskSubmit.Status"},{"location":"apis/proto/#updatestatusstatus","text":"Name Number Description UNKNOWN 0 FAILED 1 SUCCESS 2","title":"UpdateStatus.Status"},{"location":"apis/proto/#updatestatustaskstatus","text":"Name Number Description TASK_UNKNOWN 0 TASK_CANCEL 1 TASK_EXCEPTION 2 TASK_FINISH 3","title":"UpdateStatus.TaskStatus"},{"location":"apis/proto/#clustermanager","text":"service in cluster manager called by worker Method Name Request Type Response Type Description Enroll Enroll.REQ Enroll.REP stream service for worker: enroll and fetch tasks UpdateTaskStatus UpdateStatus.REQ UpdateStatus.REP service for worker: update status or heartbeat TaskSubmit TaskSubmit.REQ TaskSubmit.REP service for master: submit task to cluster TaskResourceRequire TaskResourceRequire.REQ TaskResourceRequire.REP","title":"ClusterManager"},{"location":"apis/proto/#scalar-value-types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby double double double float float64 double float Float float float float float float32 float float Float int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required) int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required) uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required) sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required) sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required) fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required) sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum bool bool boolean boolean bool bool boolean TrueClass/FalseClass string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8) bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)","title":"Scalar Value Types"},{"location":"deploy/cli/","text":"CLI \u00b6 Usage : $ [ OPTIONS ] COMMAND [ ARGS ] ... Options : --install-completion : Install completion for the current shell. --show-completion : Show completion for the current shell, to copy it or customize the installation. --help : Show this message and exit. Commands : deploy service : [start|stop] service template deploy \u00b6 Usage : $ deploy [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : deploy deploy deploy \u00b6 Usage : $ deploy deploy [ OPTIONS ] Options : --config FILE : [required] --help : Show this message and exit. service \u00b6 [start|stop] service Usage : $ service [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : all : [start|stop] all services cluster-manager : [start|stop] cluster manager service cluster-worker : [start|stop] cluster worker service coordinator : [start|stop] coordinator service master : [start|stop] master service service all \u00b6 [start|stop] all services Usage : $ service all [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start all services stop : stop all services service all start \u00b6 start all services Usage : $ service all start [ OPTIONS ] CONFIG Arguments : CONFIG : [required] Options : --help : Show this message and exit. service all stop \u00b6 stop all services Usage : $ service all stop [ OPTIONS ] CONFIG Arguments : CONFIG : [required] Options : --help : Show this message and exit. service cluster-manager \u00b6 [start|stop] cluster manager service Usage : $ service cluster-manager [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start cluster manager stop : stop cluster manager service cluster-manager start \u00b6 start cluster manager Usage : $ service cluster-manager start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR MANAGER_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] MANAGER_PORT : port number for cluster manager to serve [required] Options : --help : Show this message and exit. service cluster-manager stop \u00b6 stop cluster manager Usage : $ service cluster-manager stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR MANAGER_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] MANAGER_PORT : port number for cluster manager to serve [required] Options : --help : Show this message and exit. service cluster-worker \u00b6 [start|stop] cluster worker service Usage : $ service cluster-worker [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start cluster worker stop : stop cluster worker service cluster-worker start \u00b6 start cluster worker Usage : $ service cluster-worker start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR NAME LOCAL_IP PORT_START PORT_END MAX_TASKS CLUSTER_MANAGER_ADDRESS Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] NAME : worker name [required] LOCAL_IP : local ip [required] PORT_START : port start [required] PORT_END : port start [required] MAX_TASKS : num of maximum parallel tasks [required] CLUSTER_MANAGER_ADDRESS : cluster manager address [required] Options : --help : Show this message and exit. service cluster-worker stop \u00b6 stop cluster worker Usage : $ service cluster-worker stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR NAME Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] NAME : worker name [required] Options : --help : Show this message and exit. service coordinator \u00b6 [start|stop] coordinator service Usage : $ service coordinator [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start coordinator stop : stop coordinator service coordinator start \u00b6 start coordinator Usage : $ service coordinator start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR COORDINATOR_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] COORDINATOR_PORT : port number for coordinator to serve [required] Options : --help : Show this message and exit. service coordinator stop \u00b6 stop coordinator Usage : $ service coordinator stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR COORDINATOR_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] COORDINATOR_PORT : port number for coordinator to serve [required] Options : --help : Show this message and exit. service master \u00b6 [start|stop] master service Usage : $ service master [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start master stop : stop master service master start \u00b6 start master Usage : $ service master start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR SUBMIT_PORT PARTY_ID CLUSTER_MANAGER_ADDRESS COORDINATOR_ADDRESS Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] SUBMIT_PORT : submit port [required] PARTY_ID : party id [required] CLUSTER_MANAGER_ADDRESS : cluster manager address [required] COORDINATOR_ADDRESS : coordinator address [required] Options : --help : Show this message and exit. service master stop \u00b6 stop master Usage : $ service master stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR SUBMIT_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] SUBMIT_PORT : submit port [required] Options : --help : Show this message and exit. template \u00b6 Usage : $ template [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : generate template generate \u00b6 Usage : $ template generate [ OPTIONS ] Options : --help : Show this message and exit.","title":"cli"},{"location":"deploy/cli/#cli","text":"Usage : $ [ OPTIONS ] COMMAND [ ARGS ] ... Options : --install-completion : Install completion for the current shell. --show-completion : Show completion for the current shell, to copy it or customize the installation. --help : Show this message and exit. Commands : deploy service : [start|stop] service template","title":"CLI"},{"location":"deploy/cli/#deploy","text":"Usage : $ deploy [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : deploy","title":"deploy"},{"location":"deploy/cli/#deploy-deploy","text":"Usage : $ deploy deploy [ OPTIONS ] Options : --config FILE : [required] --help : Show this message and exit.","title":"deploy deploy"},{"location":"deploy/cli/#service","text":"[start|stop] service Usage : $ service [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : all : [start|stop] all services cluster-manager : [start|stop] cluster manager service cluster-worker : [start|stop] cluster worker service coordinator : [start|stop] coordinator service master : [start|stop] master service","title":"service"},{"location":"deploy/cli/#service-all","text":"[start|stop] all services Usage : $ service all [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start all services stop : stop all services","title":"service all"},{"location":"deploy/cli/#service-all-start","text":"start all services Usage : $ service all start [ OPTIONS ] CONFIG Arguments : CONFIG : [required] Options : --help : Show this message and exit.","title":"service all start"},{"location":"deploy/cli/#service-all-stop","text":"stop all services Usage : $ service all stop [ OPTIONS ] CONFIG Arguments : CONFIG : [required] Options : --help : Show this message and exit.","title":"service all stop"},{"location":"deploy/cli/#service-cluster-manager","text":"[start|stop] cluster manager service Usage : $ service cluster-manager [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start cluster manager stop : stop cluster manager","title":"service cluster-manager"},{"location":"deploy/cli/#service-cluster-manager-start","text":"start cluster manager Usage : $ service cluster-manager start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR MANAGER_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] MANAGER_PORT : port number for cluster manager to serve [required] Options : --help : Show this message and exit.","title":"service cluster-manager start"},{"location":"deploy/cli/#service-cluster-manager-stop","text":"stop cluster manager Usage : $ service cluster-manager stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR MANAGER_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] MANAGER_PORT : port number for cluster manager to serve [required] Options : --help : Show this message and exit.","title":"service cluster-manager stop"},{"location":"deploy/cli/#service-cluster-worker","text":"[start|stop] cluster worker service Usage : $ service cluster-worker [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start cluster worker stop : stop cluster worker","title":"service cluster-worker"},{"location":"deploy/cli/#service-cluster-worker-start","text":"start cluster worker Usage : $ service cluster-worker start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR NAME LOCAL_IP PORT_START PORT_END MAX_TASKS CLUSTER_MANAGER_ADDRESS Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] NAME : worker name [required] LOCAL_IP : local ip [required] PORT_START : port start [required] PORT_END : port start [required] MAX_TASKS : num of maximum parallel tasks [required] CLUSTER_MANAGER_ADDRESS : cluster manager address [required] Options : --help : Show this message and exit.","title":"service cluster-worker start"},{"location":"deploy/cli/#service-cluster-worker-stop","text":"stop cluster worker Usage : $ service cluster-worker stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR NAME Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] NAME : worker name [required] Options : --help : Show this message and exit.","title":"service cluster-worker stop"},{"location":"deploy/cli/#service-coordinator","text":"[start|stop] coordinator service Usage : $ service coordinator [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start coordinator stop : stop coordinator","title":"service coordinator"},{"location":"deploy/cli/#service-coordinator-start","text":"start coordinator Usage : $ service coordinator start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR COORDINATOR_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] COORDINATOR_PORT : port number for coordinator to serve [required] Options : --help : Show this message and exit.","title":"service coordinator start"},{"location":"deploy/cli/#service-coordinator-stop","text":"stop coordinator Usage : $ service coordinator stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR COORDINATOR_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] COORDINATOR_PORT : port number for coordinator to serve [required] Options : --help : Show this message and exit.","title":"service coordinator stop"},{"location":"deploy/cli/#service-master","text":"[start|stop] master service Usage : $ service master [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : start : start master stop : stop master","title":"service master"},{"location":"deploy/cli/#service-master-start","text":"start master Usage : $ service master start [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR SUBMIT_PORT PARTY_ID CLUSTER_MANAGER_ADDRESS COORDINATOR_ADDRESS Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] SUBMIT_PORT : submit port [required] PARTY_ID : party id [required] CLUSTER_MANAGER_ADDRESS : cluster manager address [required] COORDINATOR_ADDRESS : coordinator address [required] Options : --help : Show this message and exit.","title":"service master start"},{"location":"deploy/cli/#service-master-stop","text":"stop master Usage : $ service master stop [ OPTIONS ] MACHINE_SSH MACHINE_BASE_DIR SUBMIT_PORT Arguments : MACHINE_SSH : machine ssh string: user@host:port [required] MACHINE_BASE_DIR : deployed base name [required] SUBMIT_PORT : submit port [required] Options : --help : Show this message and exit.","title":"service master stop"},{"location":"deploy/cli/#template","text":"Usage : $ template [ OPTIONS ] COMMAND [ ARGS ] ... Options : --help : Show this message and exit. Commands : generate","title":"template"},{"location":"deploy/cli/#template-generate","text":"Usage : $ template generate [ OPTIONS ] Options : --help : Show this message and exit.","title":"template generate"},{"location":"framework/overview/","text":"framework \u00b6","title":"overview"},{"location":"framework/overview/#framework","text":"","title":"framework"},{"location":"release/change_log/","text":"","title":"Changelog"}]}